export const metadata = {
  title: "anthem",
  description: "Cross-media interactive experiments for live performance",
  repo: "eulersson/anthem",
  heroImage: "/work/anthem.png",
};

# Anthem

> Participative real-time graphics. Cross-media interactive experiment for
> performance shows. A blend between different techniques and technologies
> featuring generative animations.

With this project I wanted to show how computer graphics are not exclusively
for VFX or video games. I explained how we could be feeding input data in
different ways:

- Live MIDI from the artist: Feed values into shader using a VJ
  production package.
- Raspberry Pi orientation using a Sense Hat: TCP sockets.
- Tweets matching some criteria (#hashtag): image extraction and body parsing.

The idea was also to break the conventional rules that when people go see a
show they are passive, they receive the product, instead I proposed some ways
you could engage an audience to participate in the performance.

<ImageFlexRow
  flexes={[1, 2]}
  images={["/work/anthem/me.jpg", "/work/anthem/me_distorted.png"]}
  caption="Hola"
/>
